# Chinese_Word_Segmentation
This is my summer research project, collaborated by professor Mark Hopkins and me.

dump.py and FormatCleanser.py are used to retrieve English and Finnish training data from wikipedia.
ReadData.py and DataLoader.py are used to read in the training and testing data.
Embedding.py, training.py, BSME.py and FineTune.py load and train different pre-training models and classifiers and output the results.  
pku_training files are the Chinese training and testing data.
Note that since this is a two-people project, the code was written very casually with little comments. This is not how I would write my code in a big project.
